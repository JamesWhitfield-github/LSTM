{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JAMESWhitfield\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for loading the data and building the different classes of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_WDS_results(filepath):\n",
    "    \n",
    "    # Read in data\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Read in data\n",
    "    df_original = pd.read_csv(filepath)\n",
    "    \n",
    "    # Fill in NaN with the mean\n",
    "    #df.loc[:, df.columns != 'Skill Level'] = df.loc[:, df.columns != 'Skill Level'].fillna(df.mean())\n",
    "    \n",
    "    # Fill in NaN with the mean\n",
    "    df.loc[:, ['Activity Data Score',\n",
    "               'Feedback Data Score',\n",
    "              'BadgeData Data Score',\n",
    "              'Checklist Data Score',\n",
    "              'Competency Beginning Data Score',\n",
    "              'Competency Progressing Data Score',\n",
    "              'Competency Proficient Data Score',\n",
    "              'Competency Mastery Data Score',\n",
    "              'AboutMe Data Score',\n",
    "              'CVs Data Score']] = df.loc[:, ['Activity Data Score',\n",
    "               'Feedback Data Score',\n",
    "              'BadgeData Data Score',\n",
    "              'Checklist Data Score',\n",
    "              'Competency Beginning Data Score',\n",
    "              'Competency Progressing Data Score',\n",
    "              'Competency Proficient Data Score',\n",
    "              'Competency Mastery Data Score',\n",
    "              'AboutMe Data Score',\n",
    "              'CVs Data Score']].fillna(df.mean())\n",
    "    \n",
    "    # Fill in NaN with the 0\n",
    "    df.loc[:, ['Achievement Data Score',\n",
    "               'Courses Data Score',\n",
    "               'Engagement Minimum Data Score',\n",
    "              'Engagement Low Data Score',\n",
    "              'Engagement Medium Data Score',\n",
    "              'Engagement High Data Score',\n",
    "              'Learning Course Data Score',\n",
    "              'KCs Data Score']] = df.loc[:, ['Achievement Data Score',\n",
    "               'Courses Data Score',\n",
    "               'Engagement Minimum Data Score',\n",
    "              'Engagement Low Data Score',\n",
    "              'Engagement Medium Data Score',\n",
    "              'Engagement High Data Score',\n",
    "              'Learning Course Data Score',\n",
    "              'KCs Data Score']].fillna(0)\n",
    "    \n",
    "    # Generate total competency score\n",
    "    if 'Competency Beginning Data Score' in df.columns:\n",
    "        df['Competency Data Score'] = df['Competency Beginning Data Score'].fillna(0) + \\\n",
    "        (df['Competency Progressing Data Score'].fillna(0)*2) + \\\n",
    "        (df['Competency Proficient Data Score'].fillna(0)*4) + \\\n",
    "        (df['Competency Mastery Data Score'].fillna(0)*8)\n",
    "\n",
    "        # Fill in NaN where no competencies are provided\n",
    "        df.loc[pd.isna(df['Competency Beginning Data Score']) & \n",
    "                pd.isna(df['Competency Progressing Data Score']) &\n",
    "                pd.isna(df['Competency Proficient Data Score']) &\n",
    "                pd.isna(df['Competency Mastery Data Score']), 'Competency Data Score'] = None\n",
    "    else:\n",
    "        df = df\n",
    "        \n",
    "    # Generate total engagement score\n",
    "    if 'Engagement Minimum Data Score' in df.columns:\n",
    "        df['Engagement Data Score'] = df['Engagement Minimum Data Score'].fillna(0) + \\\n",
    "        (df['Engagement Low Data Score'].fillna(0)*2) + \\\n",
    "        (df['Engagement Medium Data Score'].fillna(0)*4) + \\\n",
    "        (df['Engagement High Data Score'].fillna(0)*8)\n",
    "\n",
    "        # Fill in NaN where no engagement scores are provided\n",
    "        df.loc[pd.isna(df['Engagement Minimum Data Score']) & \n",
    "                pd.isna(df['Engagement Low Data Score']) &\n",
    "                pd.isna(df['Engagement Medium Data Score']) &\n",
    "                pd.isna(df['Engagement High Data Score']), 'Engagement Data Score'] = None\n",
    "    else:\n",
    "        df = df\n",
    "    \n",
    "    # Reset the index\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    # Reset the index\n",
    "    df_original = df_original.reset_index()\n",
    "    \n",
    "    return df, df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_model(df, feature_cols):\n",
    "    \n",
    "    # Drop the NaN in the training data\n",
    "    df = df.dropna(subset=['Skill Level']).copy()\n",
    "    \n",
    "    # Split dataset in features and target variable\n",
    "    X = df[feature_cols] # Features\n",
    "    y = df['Skill Level'] # Target variable\n",
    "    \n",
    "    # Split dataset into training and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "    \n",
    "    # Instantiate the model (using the default parameters)\n",
    "    gnb = GaussianNB()\n",
    "    \n",
    "    # Define feature selection\n",
    "    #selector = RFE(gnb, step=1)\n",
    "\n",
    "    # Fit the model with data\n",
    "    gnb.fit(X_train,y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = gnb.predict(X_test)\n",
    "    y_pred = pd.DataFrame(y_pred)\n",
    "    y_pred = y_pred.rename(index=str, columns={0: \"Predictions\"})\n",
    "    \n",
    "    # Confidence\n",
    "    confidence = gnb.predict_proba(X_test)\n",
    "    confidence = confidence.max(axis=1)\n",
    "    confidence_df = pd.DataFrame(confidence)\n",
    "    confidence_df = confidence_df.rename(index=str, columns={0: \"Confidence\"})\n",
    "    y_pred = pd.merge(y_pred, confidence_df, left_index=True, right_index=True)\n",
    "    \n",
    "    # Convert y datasets to pandas dataframes\n",
    "    y_train = pd.DataFrame(data=y_train)\n",
    "    y_test = pd.DataFrame(data=y_test)\n",
    "    \n",
    "    # Set index to match y_test\n",
    "    index_vals = y_test.index.values\n",
    "    y_pred = y_pred.set_index(index_vals)\n",
    "    \n",
    "    #selections = selector.support_\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, y_pred, gnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_keyword_results(filepath,sheet):\n",
    "    \n",
    "    # Read in data\n",
    "    df = pd.read_excel(io=filepath, sheet_name=sheet)\n",
    "    \n",
    "    # Drop irrelevant columns\n",
    "    df = df.drop(columns=['Activity Data Score', 'Achievement Data Score','Courses Data Score','Engagement Data Score',\n",
    "                'Feedback Data Score','BadgeData Data Score','Competency Beginning Data Score', \n",
    "                'Competency Progressing Data Score','Competency Proficient Data Score','Competency Mastery Data Score',\n",
    "                'Learning Course Data Score','AboutMe Data Score','CVs Data Score'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_mapping = {\n",
    "    'Purchase Price Allocation (PPA)': (1, 'Purchase Price Allocation (PPA)'),\n",
    "    'Valuation': (2, 'Valuation'),\n",
    "    'Impairment Testing': (3, 'Impairment Testing'),\n",
    "    'Equity Incentives - Tax Valuati': (4, 'Equity Incentives - Tax Valuation'),\n",
    "    'Cost Benefit Analysis': (5, 'Cost Benefit Analysis'),\n",
    "    'Due Diligence': (6, 'Due Diligence'),\n",
    "    'Real estate sell-side preparati': (7, 'Real estate sell-side preparation'),\n",
    "    'Modelling': (8, 'Modelling'),\n",
    "    'Debt Options Analysis': (9, 'Debt Options Analysis'),\n",
    "    'Bid financial evaluation': (10, 'Bid financial evaluation'),\n",
    "    'Green Book business cases': (11, 'Green Book business cases'),\n",
    "    'Power Purchase Agreements (PPA': (12, 'Power Purchase Agreements (PPAs)'),\n",
    "    'Working Capital & Liquidity Imp': (13, 'Working Capital & Liquidity Improvement'),\n",
    "    'Financial Analysis Due Diligenc': (14, 'Financial Analysis Due Diligence'),\n",
    "    'Advanced Excel': (15, 'Advanced Excel'),\n",
    "    'Cash flow Forecasting': (16, 'Cash flow Forecasting'),\n",
    "    'Formal Insolvency': (17, 'Formal Insolvency'),\n",
    "    'Equity to Enterprise Value Brid': (18, 'Equity to Enterprise Value Bridges'),\n",
    "    'EBITDA Adjustment Identificatio': (19, 'EBITDA Adjustment Identification'),\n",
    "    'Debt and debt-like items analys': (20, 'Debt and debt-like items analysis'),\n",
    "    'Stock Exchange Working Capital': (21, 'Stock Exchange Working Capital'),\n",
    "    'Working capital target /peg/ normalised analysis': (22, 'Working capital target peg norm'),\n",
    "    'Project Management': (23, 'Project Management')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_results(filepath_WDS,skill,feature_cols,filepath_keyword,skill_mapping):\n",
    "    \n",
    "    # Read in data\n",
    "    df, df_original = import_WDS_results(filepath_WDS)\n",
    "    df = df.drop(['index'], axis=1)\n",
    "    df_original = df_original.drop(['index'], axis=1)\n",
    "    \n",
    "    # Build the model\n",
    "    X_train, X_test, y_train, y_test, y_pred, gnb = naive_bayes_model(df, feature_cols)\n",
    "\n",
    "    # Create table of test predictions\n",
    "    predictions_test = pd.merge(df, y_pred, left_index=True, right_index=True)\n",
    "    predictions_test['Test Flag'] = 1\n",
    "    predictions_test\n",
    "    \n",
    "    # Create table of predictions\n",
    "    X = df[feature_cols]\n",
    "    y_pred = pd.DataFrame(gnb.predict(X))\n",
    "    y_pred = y_pred.rename(index=str, columns={0: \"Predictions\"})\n",
    "    \n",
    "    # Confidence\n",
    "    confidence = gnb.predict_proba(X)\n",
    "    max_confidence = confidence.max(axis=1)\n",
    "    max_confidence_df = pd.DataFrame(max_confidence)\n",
    "    max_confidence_df = max_confidence_df.rename(index=str, columns={0: \"Confidence\"})\n",
    "    y_pred = pd.merge(y_pred, max_confidence_df, left_index=True, right_index=True)\n",
    "    \n",
    "    # Reset Index of y_pred\n",
    "    index_vals = df.index.values\n",
    "    y_pred = y_pred.set_index(index_vals)\n",
    "    \n",
    "    # Other probabilities\n",
    "    #confidence_df = pd.DataFrame(confidence, columns=['1','2','3','4','5'])\n",
    "    #y_pred = pd.merge(y_pred, confidence_df, left_index=True, right_index=True)\n",
    "    \n",
    "    # Merge test flag with predictions\n",
    "    predictions = pd.merge(df_original, y_pred, left_index=True, right_index=True)\n",
    "    if 'CVs Data Score' in predictions.columns:\n",
    "        predictions = predictions.sort_values(by=['CVs Data Score'],ascending=False)\n",
    "    else:\n",
    "        predictions = predictions.sort_values(by=['WDS Score'],ascending=False)\n",
    "    m=predictions_test[['Custom ID','Test Flag']]\n",
    "    predictions = predictions.merge(m , left_on='Custom ID', right_on='Custom ID', how='left')\n",
    "    \n",
    "    # Create Secondary Prediction\n",
    "    #twomax = predictions.loc[:,['1', '2', '3', '4', '5']]\n",
    "    #twomax['Secondary Prediction'] = (twomax.rank(axis=1, ascending=False) == 2).idxmax(axis=1).astype(int)\n",
    "    #twomax['Secondary Confidence'] = twomax[twomax.rank(axis=1, ascending=False) == 3].max(axis=1)\n",
    "    #twomax = twomax.loc[:,['Secondary Prediction','Secondary Confidence']]\n",
    "    #predictions = pd.merge(predictions, twomax, left_index=True, right_index=True)\n",
    "    #predictions = predictions.rename(index=str, columns={\"1\": \"Probability of 1\", \n",
    "                                                         #\"2\": \"Probability of 2\", \n",
    "                                                         #\"3\": \"Probability of 3\",\n",
    "                                                         #\"4\": \"Probability of 4\",\n",
    "                                                         #\"5\": \"Probability of 5\"})\n",
    "    \n",
    "    # Load keywords matched\n",
    "    df_keyword = import_keyword_results(filepath_keyword,skill)\n",
    "    \n",
    "    # Merge keywords with the predictions\n",
    "    final_df = predictions.merge(df_keyword , left_on='Custom ID', right_on='Custom ID', how='left')\n",
    "    final_df['Skill_ID'] = skill_mapping.get(skill)[0]\n",
    "    final_df['Skill_Name'] = skill_mapping.get(skill)[1]\n",
    "    \n",
    "    # Generate Result Column\n",
    "    final_df['Result_Calc'] = (final_df['Skill Level'] - final_df['Predictions'])**2\n",
    "    final_df['Result'] = 'Wrong'\n",
    "    for index, row in final_df.iterrows():\n",
    "        result = ''\n",
    "        if row['Result_Calc'] < 0.5:\n",
    "            result = 'Correct'\n",
    "        elif row['Result_Calc'] < 2:\n",
    "            result = 'Within 1'\n",
    "        elif row['Result_Calc'] < 5:\n",
    "            result = 'Within 2'\n",
    "        elif row['Result_Calc'] < 10:\n",
    "            result = 'Within 3'\n",
    "        elif row['Result_Calc'] < 17:\n",
    "            result = 'Within 4'\n",
    "        else:\n",
    "            result = ''\n",
    "        final_df.set_value(index,'Result',result)\n",
    "    final_df.drop(columns=['Result_Calc'],inplace=True)\n",
    "\n",
    "    return final_df, selections, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and run the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JAMESWhitfield\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:82: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due Diligence completed...\n",
      "Empty DataFrame\n",
      "Columns: [Skill, Activity Data Score, Achievement Data Score, Courses Data Score, Engagement Data Score, Feedback Data Score, Checklist Data Score, Learning Course Data Score, AboutMe Data Score, CVs Data Score, KCs Data Score]\n",
      "Index: []\n",
      "Project Management completed...\n",
      "Empty DataFrame\n",
      "Columns: [Skill, Activity Data Score, Achievement Data Score, Courses Data Score, Engagement Data Score, Feedback Data Score, Checklist Data Score, Learning Course Data Score, AboutMe Data Score, CVs Data Score, KCs Data Score]\n",
      "Index: []\n",
      "Real estate sell-side preparati completed...\n",
      "Empty DataFrame\n",
      "Columns: [Skill, Activity Data Score, Achievement Data Score, Courses Data Score, Engagement Data Score, Feedback Data Score, Checklist Data Score, Learning Course Data Score, AboutMe Data Score, CVs Data Score, KCs Data Score]\n",
      "Index: []\n",
      "Formal Insolvency completed...\n",
      "Empty DataFrame\n",
      "Columns: [Skill, Activity Data Score, Achievement Data Score, Courses Data Score, Engagement Data Score, Feedback Data Score, Checklist Data Score, Learning Course Data Score, AboutMe Data Score, CVs Data Score, KCs Data Score]\n",
      "Index: []\n",
      "Debt Options Analysis completed...\n",
      "Empty DataFrame\n",
      "Columns: [Skill, Activity Data Score, Achievement Data Score, Courses Data Score, Engagement Data Score, Feedback Data Score, Checklist Data Score, Learning Course Data Score, AboutMe Data Score, CVs Data Score, KCs Data Score]\n",
      "Index: []\n",
      "Modelling completed...\n",
      "Empty DataFrame\n",
      "Columns: [Skill, Activity Data Score, Achievement Data Score, Courses Data Score, Engagement Data Score, Feedback Data Score, Checklist Data Score, Learning Course Data Score, AboutMe Data Score, CVs Data Score, KCs Data Score]\n",
      "Index: []\n",
      "Impairment Testing completed...\n",
      "Empty DataFrame\n",
      "Columns: [Skill, Activity Data Score, Achievement Data Score, Courses Data Score, Engagement Data Score, Feedback Data Score, Checklist Data Score, Learning Course Data Score, AboutMe Data Score, CVs Data Score, KCs Data Score]\n",
      "Index: []\n",
      "Advanced Excel completed...\n",
      "Empty DataFrame\n",
      "Columns: [Skill, Activity Data Score, Achievement Data Score, Courses Data Score, Engagement Data Score, Feedback Data Score, Checklist Data Score, Learning Course Data Score, AboutMe Data Score, CVs Data Score, KCs Data Score]\n",
      "Index: []\n",
      "Purchase Price Allocation (PPA) completed...\n",
      "Empty DataFrame\n",
      "Columns: [Skill, Activity Data Score, Achievement Data Score, Courses Data Score, Engagement Data Score, Feedback Data Score, Checklist Data Score, Learning Course Data Score, AboutMe Data Score, CVs Data Score, KCs Data Score]\n",
      "Index: []\n",
      "Working Capital & Liquidity Imp completed...\n",
      "Empty DataFrame\n",
      "Columns: [Skill, Activity Data Score, Achievement Data Score, Courses Data Score, Engagement Data Score, Feedback Data Score, Checklist Data Score, Learning Course Data Score, AboutMe Data Score, CVs Data Score, KCs Data Score]\n",
      "Index: []\n",
      "Cash flow Forecasting completed...\n",
      "Empty DataFrame\n",
      "Columns: [Skill, Activity Data Score, Achievement Data Score, Courses Data Score, Engagement Data Score, Feedback Data Score, Checklist Data Score, Learning Course Data Score, AboutMe Data Score, CVs Data Score, KCs Data Score]\n",
      "Index: []\n",
      "Financial Analysis Due Diligenc completed...\n",
      "Empty DataFrame\n",
      "Columns: [Skill, Activity Data Score, Achievement Data Score, Courses Data Score, Engagement Data Score, Feedback Data Score, Checklist Data Score, Learning Course Data Score, AboutMe Data Score, CVs Data Score, KCs Data Score]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Inputs\n",
    "skill_list = ['Due Diligence', 'Project Management', 'Real estate sell-side preparati', 'Formal Insolvency', 'Debt Options Analysis', 'Modelling','Impairment Testing','Advanced Excel','Purchase Price Allocation (PPA)','Working Capital & Liquidity Imp','Cash flow Forecasting','Financial Analysis Due Diligenc']\n",
    "feature_cols = ['Activity Data Score','Achievement Data Score','Courses Data Score','Engagement Data Score','Feedback Data Score','Checklist Data Score','Learning Course Data Score','AboutMe Data Score','CVs Data Score','KCs Data Score']\n",
    "filepath_keyword = 'C:/Users/JAMESWhitfield/Documents/01 - Projects/15 - Ernst & Young/Models/Training_Data/PeopleFeatures_311018_13FeaturesWithKeywordsTitleBoostPurgedConceptsCV_AllSkills.xls'\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "#selections = pd.DataFrame(columns = ['Skill'] + feature_cols)\n",
    "\n",
    "for skill_i in skill_list:\n",
    "    \n",
    "    filepath_WDS = 'C:/Users/JAMESWhitfield/Documents/01 - Projects/15 - Ernst & Young/Models/Training_Data/151118/PeopleFeatures_151118_' + skill_i + '.csv'\n",
    "    skill = skill_i\n",
    "    \n",
    "    current_df, current_selections, y_pred = calculate_results(filepath_WDS,skill,feature_cols,filepath_keyword,skill_mapping)\n",
    "    \n",
    "    print(skill_i + \" completed...\")\n",
    "    \n",
    "    #print(current_selections)\n",
    "    \n",
    "    final_df = final_df.append(current_df)\n",
    "    \n",
    "    #new_row = {\n",
    "        #\"Skill\": skill_i,\n",
    "        #\"Activity Data Score\": current_selections[0],\n",
    "        #\"Achievement Data Score\": current_selections[1],\n",
    "        #\"Courses Data Score\": current_selections[2],\n",
    "        #\"Engagement Data Score\": current_selections[3],\n",
    "        #\"Feedback Data Score\": current_selections[4],\n",
    "        #\"Checklist Data Score\": current_selections[5],\n",
    "        #\"Learning Course Data Score\": current_selections[6],\n",
    "        #\"AboutMe Data Score\": current_selections[7],\n",
    "        #\"CVs Data Score\": current_selections[8],\n",
    "        #\"KCs Data Score\": current_selections[9]\n",
    "    #}\n",
    "    \n",
    "    #selections = selections.append(new_row,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write results to a csv\n",
    "final_df.to_csv('15112018_Naive_Bayes_Results_v1.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skill</th>\n",
       "      <th>Activity Data Score</th>\n",
       "      <th>Achievement Data Score</th>\n",
       "      <th>Courses Data Score</th>\n",
       "      <th>Engagement Data Score</th>\n",
       "      <th>Feedback Data Score</th>\n",
       "      <th>Checklist Data Score</th>\n",
       "      <th>Learning Course Data Score</th>\n",
       "      <th>AboutMe Data Score</th>\n",
       "      <th>CVs Data Score</th>\n",
       "      <th>KCs Data Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Skill, Activity Data Score, Achievement Data Score, Courses Data Score, Engagement Data Score, Feedback Data Score, Checklist Data Score, Learning Course Data Score, AboutMe Data Score, CVs Data Score, KCs Data Score]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selections"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
